{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes torch.Size([500, 784]) (500, 784)\n",
      "shapes torch.Size([256, 500]) (256, 500)\n",
      "shapes torch.Size([10, 256]) (10, 256)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from os.path import join as oj\n",
    "import sys\n",
    "sys.path.append('../vision_fit')\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise\n",
    "import matplotlib.pyplot as plt\n",
    "import models\n",
    "from dim_reduction import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# reduce model by projecting onto pcs that explain \"percent_to_explain\"\n",
    "def reduce_model(model, percent_to_explain=0.85):\n",
    "    model_r = deepcopy(model)\n",
    "    weight_dict = model_r.state_dict()\n",
    "    weight_dict_new = deepcopy(model_r.state_dict())\n",
    "#     print(weight_dict)\n",
    "    for layer_name in weight_dict.keys():\n",
    "        if 'weight' in layer_name:\n",
    "            w = weight_dict[layer_name]\n",
    "            \n",
    "            # get number of components\n",
    "            pca = PCA(n_components=w.shape[1])\n",
    "            pca.fit(w)\n",
    "            explained_vars = pca.explained_variance_ratio_\n",
    "            dim, perc_explained = 0, 0\n",
    "            while perc_explained <= percent_to_explain:\n",
    "                perc_explained += explained_vars[dim]\n",
    "                dim += 1\n",
    "            \n",
    "            # actually project\n",
    "            pca = PCA(n_components=dim)            \n",
    "            w2 = pca.inverse_transform(pca.fit_transform(w))\n",
    "            print('shapes', w.shape, w2.shape)\n",
    "            weight_dict_new[layer_name] = torch.Tensor(w2)\n",
    "            \n",
    "    model_r.load_state_dict(weight_dict_new)\n",
    "    return model_r\n",
    "\n",
    "             \n",
    "modelm = models.MnistNet()        \n",
    "modelr = reduce_model(modelm)\n",
    "convnet = models.LeNet()\n",
    "linnet = models.LinearNet(28*28, 4, 256, 10)\n",
    "ms = [modelm, modelr, convnet, linnet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.optim.sgd.SGD at 0x7f3cb46a0390>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for m in ms:\n",
    "#     print(models.get_weight_names(m))\n",
    "optim.SGD([x[1] for x in linnet.named_parameters()], lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in dict(linnet.named_parameters()).items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [x[1] for x in linnet.named_parameters()]\n",
    "# print([type(b) for b in a])\n",
    "print([b.requires_grad for b in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-956cfd7abb2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# a = models.Linear_then_AlexNet()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.Tensor(np.random.rand(1, 3, 224, 224)), requires_grad=True)\n",
    "# a = models.Linear_then_AlexNet()\n",
    "a.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['features.6.bias', 'features.6.weight', 'features.0.weight', 'features.10.weight', 'features.3.weight', 'features.10.bias', 'classifier.1.weight', 'classifier.6.weight', 'classifier.1.bias', 'classifier.4.weight', 'features.8.weight', 'features.8.bias', 'features.0.bias', 'classifier.4.bias', 'classifier.6.bias', 'features.3.bias']) odict_keys(['features.0.weight', 'features.0.bias', 'features.3.weight', 'features.3.bias', 'features.6.weight', 'features.6.bias', 'features.8.weight', 'features.8.bias', 'features.10.weight', 'features.10.bias', 'classifier.1.weight', 'classifier.1.bias', 'classifier.4.weight', 'classifier.4.bias', 'classifier.6.weight', 'classifier.6.bias'])\n"
     ]
    }
   ],
   "source": [
    "weight_dict = deepcopy({x[0]:x[1].data.cpu().numpy() for x in a.named_parameters()})\n",
    "print(weight_dict.keys(), a.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc.0.weight\n",
      "conv1.weight\n"
     ]
    }
   ],
   "source": [
    "# print(get_first_weight(modelm))\n",
    "print(models.get_weight_names(m2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params_vision import p\n",
    "np.random.seed(p.seed) \n",
    "torch.manual_seed(p.seed)    \n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "batch_size = 100\n",
    "root = oj('/scratch/users/vision/yu_dl/raaz.rsk/data', p.dset)\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "\n",
    "\n",
    "## load mnist dataset     \n",
    "\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "train_set = dset.MNIST(root=root, train=True, transform=trans, download=True)\n",
    "test_set = dset.MNIST(root=root, train=False, transform=trans, download=True)\n",
    "\n",
    "\n",
    "ex_nums = {}\n",
    "i = 0\n",
    "while(len(ex_nums) < 10):\n",
    "    ex_nums[train_set.train_labels[i]] = i\n",
    "    i += 1\n",
    "    \n",
    "exs = np.zeros((10, 28, 28))\n",
    "for i in range(10):\n",
    "    exs[i] = train_set.train_data[i]\n",
    "    \n",
    "# train_set.train_data = torch.Tensor(exs)\n",
    "# train_set.train_labels = torch.Tensor(np.arange(0, 10)).long()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False)\n",
    "model = models.MnistNet()  \n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(train_set.train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    Y_big[:, i] = np.array(Y_train==i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Y_big/np.sum(Y_big, axis=0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.5       , 0.66666667],\n",
       "       [3.        , 2.        , 1.66666667],\n",
       "       [6.        , 3.5       , 2.66666667]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(9).reshape((3, 3)) / np.arange(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 5\n",
      " 0\n",
      " 4\n",
      "⋮ \n",
      " 5\n",
      " 6\n",
      " 8\n",
      "[torch.LongTensor of size 60000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_set.train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 28, 28]) \n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      " 7\n",
      " 8\n",
      " 9\n",
      "[torch.LongTensor of size 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ex_nums = {}\n",
    "i = 0\n",
    "while(len(ex_nums) < 10):\n",
    "    ex_nums[train_set.train_labels[i]] = i\n",
    "    i += 1\n",
    "    \n",
    "exs = np.zeros((10, 28, 28))\n",
    "for i in range(10):\n",
    "    exs[i] = train_set.train_data[i]\n",
    "    \n",
    "train_set.train_data = torch.Tensor(exs)\n",
    "train_set.train_labels = torch.Tensor(np.arange(0, 10)).long()\n",
    "print(train_set.train_data.shape, train_set.train_labels)\n",
    "# train_set.train_labels = torch.Tensor(np.random.randint(0, 10, 60000)).long()\n",
    "# train_set.train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff3d65f8cf8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_set.train_data[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cb4ffc1c824a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "train_set.train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "d = torch.Tensor(np.random.randn(60000, 28, 28))\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.train_labels = torch.Tensor(np.random.randint(0, 10, 60000)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 4, ..., 6, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 10, 60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "test_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "13\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(bars[0])\n",
    "print(labs[0])\n",
    "print(np.max(labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "root = oj('/scratch/users/vision/yu_dl/raaz.rsk/data', 'cifar10')\n",
    "train_set = dset.CIFAR10(root=root, train=True, download=True, transform=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, int)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set.train_labels), type(train_set.train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<filter object at 0x7f537666c240>\n"
     ]
    }
   ],
   "source": [
    "print(filter(lambda p: p.requires_grad, m.parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad, modelm.parameters()), lr=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "        print(param_group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
