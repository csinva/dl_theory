{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "from os.path import join as oj\n",
    "out_dir = '/scratch/users/vision/data/gallant/vim_2_crcns'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(datafile, username, password, out_dir):\n",
    "    '''\n",
    "    Params\n",
    "    ------\n",
    "    datafile\n",
    "    '''\n",
    "    \n",
    "    URL = 'https://portal.nersc.gov/project/crcns/download/index.php'\n",
    "    login_data = dict(\n",
    "        username=username,\n",
    "        password=password,\n",
    "        fn=datafile,\n",
    "        submit='Login' \n",
    "    )\n",
    "\n",
    "    with requests.Session() as s:\n",
    "        local_filename = oj(out_dir, login_data['fn'].split('/')[-1])\n",
    "        print(local_filename)\n",
    "        r = s.post(URL, data=login_data, stream=True)\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in tqdm(r.iter_content(chunk_size=1024)):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    \n",
    "uname = 'csinva'\n",
    "pwd = 'password'\n",
    "dset = 'vim-2'\n",
    "fnames = ['Stimuli.tar.gz', 'VoxelResponses_subject1.tar.gz', 'anatomy.zip', 'checksums.md5', 'filelist.txt', 'docs']\n",
    "for fname in fnames:\n",
    "    fname = oj(dset, fname)\n",
    "#     download(fname, uname, pwd, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anatomy.zip    docs          Stimuli.mat     VoxelResponses_subject1.mat\n",
      "checksums.md5  filelist.txt  Stimuli.tar.gz  VoxelResponses_subject1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "ls /scratch/users/vision/data/gallant/vim_2_crcns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.9G\t/scratch/users/vision/data/gallant/vim_2_crcns\n"
     ]
    }
   ],
   "source": [
    "!du -sh /scratch/users/vision/data/gallant/vim_2_crcns\n",
    "# next extract the tars\n",
    "# next unzip the zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /scratch/users/vision/data/gallant/vim_2_crcns/*.gz |xargs -n1 tar -xzf # extract the tar files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# view responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables, numpy\n",
    "f = tables.open_file(oj(out_dir, 'VoxelResponses_subject1.mat'))\n",
    "# f.listNodes # Show all variables available\n",
    "data = f.get_node('/rt')[:]\n",
    "roi = f.get_node('/roi/v1lh')[:].flatten()\n",
    "v1lh_idx = numpy.nonzero(roi==1)[0]\n",
    "v1lh_resp = data[v1lh_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1lh_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494, 7200)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1lh_resp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# view images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import data\n",
    "from skimage.util import img_as_float\n",
    "from skimage.filters import gabor_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare filter bank kernels\n",
    "kernels = []\n",
    "for theta in range(4):\n",
    "    theta = theta / 4. * np.pi\n",
    "    for sigma in (1, 3):\n",
    "        for frequency in (0.05, 0.25):\n",
    "            kernel = gabor_kernel(frequency, theta=theta,\n",
    "                                          sigma_x=sigma, sigma_y=sigma)\n",
    "            kernels.append(kernel)\n",
    "\n",
    "\n",
    "shrink = (slice(0, None, 3), slice(0, None, 3))\n",
    "brick = img_as_float(data.brick())[shrink]\n",
    "grass = img_as_float(data.grass())[shrink]\n",
    "gravel = img_as_float(data.gravel())[shrink]\n",
    "image_names = ['brick', 'grass', 'gravel']\n",
    "images = [brick, grass, gravel]\n",
    "\n",
    "\n",
    "def feats(image, kernel):\n",
    "    \n",
    "    '''power calculation\n",
    "    image = (image - image.mean()) / image.std()\n",
    "    return np.sqrt(ndi.convolve(image, np.real(kernel), mode='wrap')**2 +\n",
    "                   ndi.convolve(image, np.imag(kernel), mode='wrap')**2)\n",
    "    '''\n",
    "    mag = np.sqrt(ndi.convolve(image, np.real(kernel), mode='wrap')**2 +\n",
    "                  ndi.convolve(image, np.imag(kernel), mode='wrap')**2)\n",
    "    return np.log(1 + mag)\n",
    "\n",
    "# Plot a selection of the filter bank kernels and their responses.\n",
    "results = []\n",
    "kernel_params = []\n",
    "for theta in [0, 1]:\n",
    "    theta = theta / 4. * np.pi\n",
    "    for frequency in [0.1, 0.4]:\n",
    "        kernel = gabor_kernel(frequency, theta=theta)\n",
    "        params = 'theta=%d,\\nfrequency=%.2f' % (theta * 180 / np.pi, frequency)\n",
    "        kernel_params.append(params)\n",
    "        results.append((kernel, [feats(img, kernel) for img in images])) # Save kernel and the power image for each image\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(5, 6), dpi=200)\n",
    "# plt.gray()\n",
    "fig.suptitle('Image responses for Gabor filter kernels', fontsize=12)\n",
    "\n",
    "axes[0][0].axis('off')\n",
    "\n",
    "\n",
    "# Plot original images\n",
    "for label, img, ax in zip(image_names, images, axes[0][1:]):\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(label, fontsize=9)\n",
    "    ax.axis('off')\n",
    "\n",
    "for label, (kernel, feats), ax_row in zip(kernel_params, results, axes[1:]):\n",
    "    # Plot Gabor kernel\n",
    "    ax = ax_row[0]\n",
    "    ax.imshow(np.real(kernel))\n",
    "    ax.set_ylabel(label, fontsize=7)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "for label, (kernel, feats), ax_row in zip(kernel_params, results, axes[1:]):\n",
    "    # Plot Gabor kernel\n",
    "    ax = ax_row[2]\n",
    "    ax.imshow(np.imag(kernel))\n",
    "    ax.set_ylabel(label, fontsize=7)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Plot Gabor responses with the contrast normalized for each filter\n",
    "    vmin = np.min(feats)\n",
    "    vmax = np.max(feats)\n",
    "    for patch, ax in zip(feats, ax_row[1:]):\n",
    "        ax.imshow(patch, vmin=vmin, vmax=vmax)\n",
    "        ax.axis('off')  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pycortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cortex\n",
    "from cortex import surfs\n",
    "# ds = cortex.load(oj(out_dir, 'anatomy/S1_anatomy.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = cortex.load(\"S1_retinotopy.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: h5ls: not found\n"
     ]
    }
   ],
   "source": [
    "!h5ls S1_retinotopy.hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cortex.webshow(cortex.Volume.random(\"S1\", \"fullhead\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts, poly = surfs.getSurf(\"AH\", \"fiducial\", merge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nilearn plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(64, 64, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_glass_brain(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset created in /accounts/projects/vision/nilearn_data/neurovault\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/accounts/projects/vision/nilearn_data/neurovault/collection_658/image_10426.nii.gz'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motor_images = datasets.fetch_neurovault_motor_task()\n",
    "stat_img = motor_images.images[0]\n",
    "# stat_img is just the name of the file that we downloded\n",
    "stat_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/accounts/projects/vision/nilearn_data/neurovault/collection_658/image_10426.nii.gz'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
