{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join as oj\n",
    "import sys, time\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load in imagenet dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dset...\n",
      "done loading dset\n"
     ]
    }
   ],
   "source": [
    "# Data loading code\n",
    "data_dir = '/scratch/users/vision/data/cv/imagenet_full'\n",
    "traindir = os.path.join(data_dir, 'train')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "batch_size = 10\n",
    "num_workers = 1\n",
    "\n",
    "t = time.clock()\n",
    "print('loading dset...')\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dset.ImageFolder(traindir, transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize])), \n",
    "    batch_size=batch_size, shuffle=False,\n",
    "    num_workers=num_workers, pin_memory=True)\n",
    "'''\n",
    "valdir = os.path.join(data_dir, 'val')\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dset.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize])),\n",
    "    batch_size=batch_size, shuffle=False, \n",
    "    num_workers=num_workers, pin_memory=True)\n",
    "'''\n",
    "print('done loading dset', time.clock() - t, 'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load in some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(s):\n",
    "    if s == 'densenet':\n",
    "        model = models.densenet161(pretrained=True)\n",
    "    elif s == 'alexnet':\n",
    "        model = models.alexnet(pretrained=True)\n",
    "    elif s == 'resnet18':\n",
    "        model = models.resnet18(pretrained=True)\n",
    "    elif s == 'vgg16':\n",
    "        model = models.vgg16(pretrained=True)\n",
    "    elif s == 'inception_v3':\n",
    "        model = models.inception_v3(pretrained=True)\n",
    "    return model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ims_shape torch.Size([10, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# calculate max corrs for a linear layer\n",
    "def linear_hook(module, act_in, act_out):\n",
    "    # b is batch_size\n",
    "    # input is (b x in_size)\n",
    "    # weight is (out_size x in_size)\n",
    "    # output is (out_1, ...., out_b)\n",
    "    \n",
    "    act_in_norm = act_in[0].t() / torch.norm(act_in[0], dim=1) # normalize each of b rows\n",
    "    act_in_norm = act_in_norm.t() # transpose back to b x in_size\n",
    "    \n",
    "    Y = torch.matmul(act_in_norm, module.weight.t()) # Y is (b x out_size)\n",
    "    \n",
    "    corrs = torch.max(Y, dim=0)[0] # b (1-d)\n",
    "    \n",
    "    if not module.name in max_corrs:\n",
    "        max_corrs[module.name] = corrs\n",
    "    else:\n",
    "        max_corrs[module.name] = torch.max(corrs, max_corrs[module.name]) # element wise max\n",
    "        \n",
    "# calculate max corrs for a conv layer\n",
    "def conv_hook(module, act_in, act_out):\n",
    "    # b is batch_size\n",
    "    # input is (b x in_num_filters x H x W)    \n",
    "    # weight is (out_num_filters x in_num_filters x Hconv x Wconv)\n",
    "    # output is (out_shape_1, ...., out_shape_b) where out_shape_1 is out_num_filters x Hout x Wout\n",
    "    raise NotImplemented\n",
    "\n",
    "\n",
    "max_corrs = {}\n",
    "model = get_model('alexnet')\n",
    "# list(model.modules())\n",
    "\n",
    "# pick some layers\n",
    "lays = [model.classifier[1], model.classifier[4], model.classifier[6]]\n",
    "names = ['fc1', 'fc2', 'fc3']\n",
    "\n",
    "\n",
    "for i, lay in enumerate(lays):\n",
    "    lay.name = names[i]\n",
    "    \n",
    "    if 'fc' in lay.name:\n",
    "        lay.register_forward_hook(linear_hook)\n",
    "#     elif 'conv' in lay.name:\n",
    "#         lay.register_forward_hook(conv_hook)        \n",
    "\n",
    "# run - training set is about 14 mil\n",
    "for i, x in enumerate(val_loader):\n",
    "    ims = x[0].cuda()\n",
    "    _ = model(ims)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        pkl.dump(max_corrs, open(oj('max_corrs', 'alexnet_' + str(i) + '.pkl'), 'wb'))\n",
    "    # \n",
    "# calc_max_corr(val_loader, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# still need to normalize by w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
