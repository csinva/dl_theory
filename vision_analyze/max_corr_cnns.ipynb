{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join as oj\n",
    "import sys, time\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "sys.path.insert(1, oj(sys.path[0], '../vision_fit'))  # insert parent path\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import data\n",
    "from max_corr_cnns import get_model_pretrained, lays_and_names\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = os.listdir('./max_corrs')\n",
    "model_names = ['densenet', 'alexnet', 'resnet18', 'vgg16', 'inception_v3']\n",
    "print('Model & Layer & Dim (RxC) & $||W_F||$ & Stable Rank & Mem. Coef. \\\\\\\\')\n",
    "for model_name in model_names:\n",
    "    fnames_m = [fname for fname in fnames if model_name in fname]\n",
    "    if len(fnames_m) == 1:\n",
    "        max_corrs = pkl.load(open(oj('max_corrs', fnames_m[0]), \"rb\"))\n",
    "        lays, lay_names = lays_and_names(model_name)\n",
    "        for lay, lay_name in zip(lays, lay_names):\n",
    "            max_corr = max_corrs[lay_name]\n",
    "            w = lay.weight            \n",
    "            max_corr_norm = max_corr / w.norm(dim=1)\n",
    "            svs = w.svd(compute_uv=False)[1].detach().cpu().numpy()**2\n",
    "            print(model_name, '&', lay_name, '&', w.shape[0], 'x', w.shape[1],\n",
    "                  '&', round(w.norm().item(), 2), '&', np.sum(svs) / np.max(svs),\n",
    "                  '&', round(max_corr_norm.mean().item(), 3), '\\\\\\\\')\n",
    "    else:\n",
    "        pass\n",
    "#         print(model_name, len(fnames_m), 'files found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load in imagenet dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading imagenet train dset...\n",
      "done loading train dset 14.289691000000033 sec\n"
     ]
    }
   ],
   "source": [
    "class p: pass\n",
    "p.batch_size = 100\n",
    "p.dset = 'imagenet'\n",
    "train_loader, val_loader = data.get_data_loaders(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate max corrs for a linear layer\n",
    "def linear_hook(module, act_in, act_out):\n",
    "    # b is batch_size\n",
    "    # input is (b x in_size)\n",
    "    # weight is (out_size x in_size)\n",
    "    # output is (out_1, ...., out_b)\n",
    "    print(module.name)\n",
    "    act_in_norm = act_in[0].t() / torch.norm(act_in[0], dim=1) # normalize each of b rows\n",
    "    act_in_norm = act_in_norm.t() # transpose back to b x in_size\n",
    "    \n",
    "    Y = torch.matmul(act_in_norm, module.weight.t()) # Y is (b x out_size)\n",
    "    \n",
    "    corrs = torch.max(Y, dim=0)[0] # b (1-d)\n",
    "    \n",
    "    if not module.name in max_corrs:\n",
    "        max_corrs[module.name] = corrs\n",
    "    else:\n",
    "        max_corrs[module.name] = torch.max(corrs, max_corrs[module.name]) # element wise max\n",
    "    \n",
    "model_name = 'vgg11' # alexnet, vgg16, inception_v3, resnet18, densenet\n",
    "model = get_model_pretrained(model_name)\n",
    "lays, names = lays_and_names(model_name)\n",
    "for i, lay in enumerate(lays):\n",
    "    lay.name = names[i]\n",
    "    lay.register_forward_hook(linear_hook)\n",
    "                              \n",
    "max_corrs = {}   \n",
    "\n",
    "# run - training set is about 14 mil\n",
    "for i, x in enumerate(val_loader):\n",
    "    ims = x[0].cuda()\n",
    "    _ = model(ims)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
