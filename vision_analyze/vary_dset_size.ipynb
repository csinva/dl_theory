{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as oj\n",
    "import sys, time\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "sys.path.insert(1, oj(sys.path[0], '..', 'vision_fit'))  # insert parent path\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import math\n",
    "# plt.style.use('dark_background')\n",
    "from mog_fit import data\n",
    "from collections import OrderedDict\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from mog_analyze import viz\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from vision_fit import data\n",
    "\n",
    "import viz_weights\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import style\n",
    "cb = '#33ccff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.set_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load results from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depending on how much is saved, this may take a while\n",
    "# out_dir = '/scratch/users/vision/yu_dl/raaz.rsk/track_acts/dsets_small'\n",
    "out_dir = '/scratch/users/vision/yu_dl/raaz.rsk/track_acts/dsets_small_rerun'\n",
    "fnames = sorted([fname for fname in os.listdir(out_dir) ])\n",
    "#                  if not 'mnist' in fname and \n",
    "#                  'numlays=4' in fname and \n",
    "#                  'batchsize=100' in fname and not 'batchsize=1000' in fname])\n",
    "#                   and \n",
    "#                  'numlays=4' in fname]) # and \n",
    "#                  'batchsize=100' in fname and \n",
    "#                  not 'batchsize=1000' in fname])\n",
    "# weights_list = [pd.Series(pkl.load(open(oj(out_dir, fname), \"rb\"))) for fname in tqdm(fnames) \n",
    "#                 if fname.startswith('weights')]\n",
    "# results_weights = pd.concat(weights_list, axis=1).T.infer_objects()\n",
    "\n",
    "results_list = [pd.Series(pkl.load(open(oj(out_dir, fname), \"rb\"))) for fname in tqdm(fnames) \n",
    "                if not fname.startswith('weights') and not fname.startswith('idx')]\n",
    "results = pd.concat(results_list, axis=1).T.infer_objects()\n",
    "\n",
    "save_dir = 'results_weights'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "# print('loaded', results_weights.shape[0], 'runs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*add cols*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = results[(results.num_points == 10)].index\n",
    "for idx in idxs:\n",
    "    results.iloc[idx]['accs_train'] *= 10\n",
    "    results.iloc[idx]['losses_train'] *= 10    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_results import process_results\n",
    "its, ts, results = process_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot max corrs\n",
    "*note some things disappear in below plot as a result of nans*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = results\n",
    "# r = results[results.seed == 0]\n",
    "# r = results[results.num_layers == 4]\n",
    "# print(r[['lr', 'first_layer_lr_mult', 'corr0_final']])\n",
    "hue = 'num_points'\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "R, C = 2, 2\n",
    "rm = r[r.dset == 'mnist_small']\n",
    "plt.subplot(R, C, 1)\n",
    "plt.title('mnist')\n",
    "\n",
    "sns.scatterplot(rm.max_test_acc, rm.corr0_final, hue=rm[hue], alpha=0.5)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.subplot(R, C, 2)\n",
    "plt.title('mnist')\n",
    "sns.scatterplot(rm.max_test_acc, rm.corr1_final, hue=rm[hue])\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "\n",
    "rm = r[r.dset == 'cifar10_small']\n",
    "# rm = rm[rm.max_test_acc > 0.4]\n",
    "plt.subplot(R, C, 3)\n",
    "plt.title('cifar')\n",
    "sns.scatterplot(rm.max_test_acc, rm.corr0_final, hue=rm[hue])\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.subplot(R, C, 4)\n",
    "plt.title('cifar')\n",
    "sns.scatterplot(rm.max_test_acc, rm.corr1_final, hue=rm[hue])\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# track things over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = results\n",
    "r = r[(r.dset == 'mnist_small') * (r.seed == 0)]\n",
    "r = r[r.max_train_acc > 0.999]\n",
    "# print(r.seed)\n",
    "\n",
    "R, C = 2, 5\n",
    "plt.figure(figsize=(20, 9.5), facecolor='w')\n",
    "xlim = 1000\n",
    "# cs_5 = {1: '#f0f9e8', 2: '#bae4bc', 5: '#7bccc4', 10: '#43a2ca', 20: '#0868ac'}\n",
    "cs_5 = {10: '#bae4bc', 100: '#7bccc4', 1000: '#0668ac'}\n",
    "vals = ['accs_train', 'accs_test', 'corr0', 'corr1', 'fc0_fro', 'fc1_fro', 'fc0_stab_rank', 'fc1_stab_rank', 'act0_stab_rank', 'act1_stab_rank']\n",
    "val_labs = ['Train Acc', 'Test Acc', '$\\\\rho_{mem}(W_1)$', '$\\\\rho_{mem}(W_2)$', \n",
    "        '$||W_1||_F$', '$||W_2||_F$', 'Stable rank($||W_1||$)', 'Stable rank($||W_2||$)', 'Stable rank($||A_1||$)', 'Stable rank($||A_2||$)']\n",
    "hue = 'num_points'\n",
    "a = 0.5\n",
    "# well-behaved\n",
    "for j, (_, row) in enumerate(r.iterrows()):\n",
    "\n",
    "    for i, val in enumerate(vals):\n",
    "        plt.subplot(R, C, i+1)\n",
    "        lab = row.optimizer.upper() + ', ' + str(row[hue])\n",
    "        try:\n",
    "            if row.optimizer == 'adam':\n",
    "                plt.plot(ts, row[val], '--', color=cs_5[row[hue]], label=lab, alpha=0.9)\n",
    "            else:\n",
    "                plt.plot(ts, row[val], color=cs_5[row[hue]], label=lab, alpha=0.9)\n",
    "        except:\n",
    "            if row.optimizer == 'adam':            \n",
    "                plt.plot(row.its[:row[val].size], row[val], '--', color=cs_5[row[hue]], label=lab, alpha=0.9)\n",
    "            else:\n",
    "                plt.plot(row.its[:row[val].size], row[val], color=cs_5[row[hue]], label=lab, alpha=0.9)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel(val_labs[i])\n",
    "        plt.xlim((0, xlim))\n",
    "\n",
    "plt.subplot(R, C, 1)\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = OrderedDict(zip(labels, handles))\n",
    "keys = ['SGD, 10', 'ADAM, 10', 'SGD, 100', 'ADAM, 100', 'SGD, 100', 'ADAM, 1000']\n",
    "vs = [by_label[key] for key in keys]\n",
    "plt.legend(vs, keys)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('vary_dset_size.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
