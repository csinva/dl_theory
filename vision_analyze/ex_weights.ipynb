{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as oj\n",
    "import sys, time\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "sys.path.insert(1, oj(sys.path[0], '..', 'vision_fit'))  # insert parent path\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import math\n",
    "# plt.style.use('dark_background')\n",
    "from mog_fit import data\n",
    "from collections import OrderedDict\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from mog_analyze import viz\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from vision_fit import data\n",
    "import viz_weights\n",
    "from process_results import process_results\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import style\n",
    "cb = '#008fd5'\n",
    "cr = '#fc4f30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.set_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load results from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3034/3034 [00:39<00:00, 77.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3034, 54)\n"
     ]
    }
   ],
   "source": [
    "# depending on how much is saved, this may take a while\n",
    "out_dir = '/scratch/users/vision/yu_dl/raaz.rsk/track_acts/resweep_full_new'\n",
    "out_dir2 = '/scratch/users/vision/yu_dl/raaz.rsk/track_acts/resweep_full_new2'\n",
    "fnames = sorted([oj(out_dir, fname) for fname in os.listdir(out_dir) \\\n",
    "                 if not fname.startswith('weights') \\\n",
    "                 and not fname.startswith('idx')]) + \\\n",
    "         sorted([oj(out_dir2, fname) for fname in os.listdir(out_dir2) \\\n",
    "                 if not fname.startswith('weights') \\\n",
    "                 and not fname.startswith('idx')])    \n",
    "results_list = [pd.Series(pkl.load(open(fname, \"rb\"))) for fname in tqdm(fnames) \n",
    "                if not fname.startswith('weights') and not fname.startswith('idx')]\n",
    "results = pd.concat(results_list, axis=1).T.infer_objects()\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**add cols**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (3034, 54)\n",
      "after (2856, 84)\n"
     ]
    }
   ],
   "source": [
    "# adds these vec keys: fc0_fro, fc1_fro, fc0_stab_rank, fc1_stab_rank, act0_stab_rank, act1_stab_rank, corr0, corr1\n",
    "# adds these scalar keys: max_train_acc, max_test_acc, _final of all the above\n",
    "print('before', results.shape)\n",
    "its, ts, results = process_results(results)\n",
    "print('after', results.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot max corrs\n",
    "*note some things disappear in below plot as a result of nans*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = results\n",
    "r = r[r.dset == 'mnist']\n",
    "r = r[r.hidden_size == 128]\n",
    "r = r[r.max_test_acc >= 0.97]\n",
    "hue = 'optimizer'\n",
    "\n",
    "R, C = 1, 1\n",
    "plt.figure(figsize=(14, 14), facecolor='w', dpi=100)\n",
    "plt.subplot(R, C, 1)\n",
    "plt.title('mnist')\n",
    "\n",
    "x = np.array(r.max_test_acc)\n",
    "y = np.array(r.corr0_final)\n",
    "pids = np.array([pid[:5] for pid in r.pid])\n",
    "ax = sns.scatterplot(x, y, hue=r[hue])\n",
    "\n",
    "for i, pid in enumerate(pids):\n",
    "    ax.annotate(pid, (x[i], y[i]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pick examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s 40043048138378577087\n",
      "a 24421020350011741116\n"
     ]
    }
   ],
   "source": [
    "pre_a = '24421'\n",
    "pre_s = '40043'\n",
    "\n",
    "r = results\n",
    "for pid in r.pid:\n",
    "    if pid.startswith(pre_a):\n",
    "        print('a', pid)\n",
    "    if pid.startswith(pre_s):\n",
    "        print('s', pid)\n",
    "\n",
    "# good for 128\n",
    "# pid_a = '24421020350011741116'\n",
    "# pid_s = '40043048138378577087'\n",
    "\n",
    "# good for 512\n",
    "pid_a = '07665771801545027002'\n",
    "pid_s = '24656068102223723425'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depending on how much is saved, this may take a while\n",
    "out_dir = '/scratch/users/vision/yu_dl/raaz.rsk/track_acts/resweep_full_new'\n",
    "out_dir2 = '/scratch/users/vision/yu_dl/raaz.rsk/track_acts/resweep_full_new2'\n",
    "fnames = sorted([oj(out_dir, fname) for fname in os.listdir(out_dir) \\\n",
    "                 if (pid_a in fname or pid_s in fname)]) + \\\n",
    "         sorted([oj(out_dir2, fname) for fname in os.listdir(out_dir2) \\\n",
    "                 if (pid_a in fname or pid_s in fname)])\n",
    "\n",
    "# weights\n",
    "fnames_w = [fname for fname in fnames if 'weights' in fname]\n",
    "results_list = [pd.Series(pkl.load(open(fname, \"rb\"))) for fname in fnames_w]\n",
    "rw = pd.concat(results_list, axis=1).T.infer_objects()\n",
    "\n",
    "# normal results\n",
    "fnames_acc = [fname for fname in fnames if '/pid' in fname] # normal results\n",
    "results_list = [pd.Series(pkl.load(open(fname, \"rb\"))) for fname in fnames_acc]\n",
    "r = pd.concat(results_list, axis=1).T.infer_objects()\n",
    "its, ts, r = process_results(r)\n",
    "\n",
    "# get individual weights\n",
    "rw_sgd = rw[rw.optimizer == 'sgd'].reset_index().iloc[0]\n",
    "rw_adam = rw[rw.optimizer == 'adam'].reset_index().iloc[0]\n",
    "\n",
    "# get accs\n",
    "r_sgd = r[r.optimizer == 'sgd'].reset_index().iloc[0]\n",
    "r_adam = r[r.optimizer == 'adam'].reset_index().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9706 0.9704 0.9999333333333333 0.9996833333333334\n",
      "sgd [0.9999] [0.9692]\n",
      "adam [0.99951667] [0.9679]\n"
     ]
    }
   ],
   "source": [
    "epoch = int(max(ts))\n",
    "print(r_sgd.max_test_acc, r_adam.max_test_acc, r_sgd.max_train_acc, r_adam.max_train_acc)\n",
    "print('sgd', r_sgd.accs_train[its == epoch], r_sgd.accs_test[its == epoch])\n",
    "print('adam', r_adam.accs_train[its == epoch], r_adam.accs_test[its == epoch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remake weight plots with hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import NullLocator\n",
    "\n",
    "def get_w(run):\n",
    "    run['num_layer'] = int(run['num_layers'])\n",
    "    run['hidden_size'] = int(run['hidden_size'])\n",
    "    lay = 'fc.0.weight'\n",
    "\n",
    "    # keys are epochs, vals are dicts of all weights\n",
    "    weights_dict_dict = run['weights']\n",
    "\n",
    "    # keys are layers, vals are weight values\n",
    "#     print(weights_dict_dict.keys())\n",
    "    weights_dict = weights_dict_dict[epoch]\n",
    "#     print(weights_dict.keys())\n",
    "    w = weights_dict[lay]\n",
    "\n",
    "    return w\n",
    "\n",
    "for run in [rw_sgd, rw_adam]:\n",
    "    w = get_w(run)\n",
    "    # matrix of weights (output x input)\n",
    "    viz_weights.plot_weights(w, dset='mnist', C=18, dpi=120)\n",
    "                \n",
    "    plt.gca().set_axis_off()\n",
    "    plt.gca().xaxis.set_major_locator(NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(NullLocator())\n",
    "    plt.margins(0, 0)\n",
    "\n",
    "    plt.savefig(run.optimizer + '_' + str(run.hidden_size) + '_' + 'w0.pdf', \n",
    "                bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_opt in [r_sgd, r_adam]:\n",
    "    max_corrs = r_opt['mean_max_corrs'][epoch]['fc.0.weight']['max_corrs']\n",
    "    plt.figure(facecolor='w')\n",
    "    plt.hist(max_corrs, density=True)\n",
    "    plt.axvline(np.mean(max_corrs), color='red')\n",
    "    plt.xlim(0, 1)\n",
    "    plt.xlabel('$\\\\rho_{mem}(W_1)$')\n",
    "    plt.ylabel('Densiy')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(r_opt.optimizer + '_' + 'hist.pdf')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*sort the weights by highest mem to lowest mem*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_opt, run in zip([r_sgd, r_adam], [rw_sgd, rw_adam]):\n",
    "    max_corrs = r_opt['mean_max_corrs'][epoch]['fc.0.weight']['max_corrs']\n",
    "    w = get_w(run)\n",
    "    inds = max_corrs.argsort()\n",
    "    max_corrs = max_corrs[inds[::-1]]\n",
    "    w = w[inds[::-1]]\n",
    "    viz_weights.plot_weights(w, dset='mnist', C=18, dpi=120)\n",
    "    \n",
    "    plt.savefig(run.optimizer + '_sorted_' + str(run.hidden_size) + '_' + 'w0.pdf', \n",
    "            bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make alterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all info in [r_sgd, r_adam], [rw_sgd, rw_adam]\n",
    "\n",
    "# load model\n",
    "model = data.get_model(run)\n",
    "\n",
    "train_loader, test_loader = data.get_data_loaders(run)\n",
    "X_train, Y_train, X_test, Y_test = calc_max_corr.process_loaders(train_loader, test_loader)\n",
    "\n",
    "# load in weights\n",
    "weights_dict_tensors = {k: torch.Tensor(v) for k, v in weights_dict.items()}\n",
    "model.load_state_dict(weights_dict_tensors)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.cpu().numpy().reshape(X_train.shape[0], -1)[:1000]\n",
    "Y = Y_train[:1000]\n",
    "X = X[Y.argsort()] # sort X by class\n",
    "W1 = model.state_dict()['fc.0.weight'].cpu().numpy()\n",
    "Z = X @ W1.T\n",
    "\n",
    "# Z[:, -50:] = np.tile(Y[Y.argsort()], 50).reshape(-1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(Variable(X_train)).data.cpu().numpy().argmax(axis=1)\n",
    "accs = preds==Y_train\n",
    "print('mean acc', np.mean(accs))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
