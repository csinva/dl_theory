{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join as oj\n",
    "import sys, time\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "sys.path.insert(1, oj(sys.path[0], '..', 'vision_fit'))  # insert parent path\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import math\n",
    "# plt.style.use('dark_background')\n",
    "from mog_fit import data\n",
    "from collections import OrderedDict\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from mog_analyze import viz\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from vision_fit import data\n",
    "import viz_weights\n",
    "from process_results import process_results\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import style\n",
    "cb = '#008fd5'\n",
    "cr = '#fc4f30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.set_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load results from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depending on how much is saved, this may take a while\n",
    "out_dir = '/scratch/users/vision/yu_dl/raaz.rsk/track_acts/resweep_full_new'\n",
    "out_dir2 = '/scratch/users/vision/yu_dl/raaz.rsk/track_acts/resweep_full_new2'\n",
    "fnames = sorted([oj(out_dir, fname) for fname in os.listdir(out_dir) \\\n",
    "                 if not fname.startswith('weights') \\\n",
    "                 and not fname.startswith('idx')]) + \\\n",
    "         sorted([oj(out_dir2, fname) for fname in os.listdir(out_dir2) \\\n",
    "                 if not fname.startswith('weights') \\\n",
    "                 and not fname.startswith('idx')])    \n",
    "\n",
    "results_list = [pd.Series(pkl.load(open(fname, \"rb\"))) for fname in tqdm(fnames) \n",
    "                if not fname.startswith('weights') and not fname.startswith('idx')]\n",
    "results = pd.concat(results_list, axis=1).T.infer_objects()\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**add cols**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (3034, 54)\n",
      "after (2856, 84)\n"
     ]
    }
   ],
   "source": [
    "# adds these vec keys: fc0_fro, fc1_fro, fc0_stab_rank, fc1_stab_rank, act0_stab_rank, act1_stab_rank, corr0, corr1\n",
    "# adds these scalar keys: max_train_acc, max_test_acc, _final of all the above\n",
    "print('before', results.shape)\n",
    "its, ts, results = process_results(results)\n",
    "print('after', results.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot max corrs\n",
    "*note some things disappear in below plot as a result of nans*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = results\n",
    "r = r[r.dset == 'mnist']\n",
    "r = r[r.hidden_size == 128]\n",
    "r = r[r.max_test_acc >= 0.97]\n",
    "hue = 'optimizer'\n",
    "\n",
    "R, C = 1, 1\n",
    "plt.figure(figsize=(14, 14), facecolor='w', dpi=100)\n",
    "plt.subplot(R, C, 1)\n",
    "plt.title('mnist')\n",
    "\n",
    "x = np.array(r.max_test_acc)\n",
    "y = np.array(r.corr0_final)\n",
    "pids = np.array([pid[:5] for pid in r.pid])\n",
    "ax = sns.scatterplot(x, y, hue=r[hue])\n",
    "\n",
    "for i, pid in enumerate(pids):\n",
    "    ax.annotate(pid, (x[i], y[i]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pick examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s 40043048138378577087\n",
      "a 24421020350011741116\n"
     ]
    }
   ],
   "source": [
    "pre_a = '24421'\n",
    "pre_s = '40043'\n",
    "\n",
    "for pid in r.pid:\n",
    "    if pid.startswith(pre_a):\n",
    "        print('a', pid)\n",
    "    if pid.startswith(pre_s):\n",
    "        print('s', pid)\n",
    "\n",
    "# good for 128\n",
    "# pid_a = '24421020350011741116'\n",
    "# pid_s = '40043048138378577087'\n",
    "\n",
    "# good for 512\n",
    "pid_a = '07665771801545027002'\n",
    "pid_s = '24656068102223723425'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['batch_size', 'calc_activations', 'dset', 'first_layer_lr_mult',\n",
      "       'freeze', 'hidden_size', 'its', 'lr', 'lr_step', 'lr_ticks',\n",
      "       'num_iters', 'num_iters_small', 'num_layers', 'num_points', 'optimizer',\n",
      "       'out_dir', 'pid', 'save_acts_and_reduce', 'save_all_freq',\n",
      "       'save_all_weights_freq', 'saves_per_iter', 'saves_per_iter_end', 'seed',\n",
      "       'shuffle_labels', 'use_conv', 'use_conv_special', 'weights',\n",
      "       'weights_first10'],\n",
      "      dtype='object')\n",
      "0    512\n",
      "1    512\n",
      "Name: hidden_size, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# depending on how much is saved, this may take a while\n",
    "out_dir = '/scratch/users/vision/yu_dl/raaz.rsk/track_acts/resweep_full_new'\n",
    "out_dir2 = '/scratch/users/vision/yu_dl/raaz.rsk/track_acts/resweep_full_new2'\n",
    "fnames = sorted([oj(out_dir, fname) for fname in os.listdir(out_dir) \\\n",
    "                 and (pid_a in fname or pid_s in fname)]) + \\\n",
    "         sorted([oj(out_dir2, fname) for fname in os.listdir(out_dir2) \\\n",
    "                 and (pid_a in fname or pid_s in fname)])\n",
    "\n",
    "fnames_w = [fname for fname in fnames if fname.startswith('weights')]\n",
    "\n",
    "results_list = [pd.Series(pkl.load(open(fname, \"rb\"))) for fname in fnames_w]\n",
    "rw = pd.concat(results_list, axis=1).T.infer_objects()\n",
    "\n",
    "rw_sgd = rw[rw.optimizer == 'sgd'].reset_index().iloc[0]\n",
    "rw_adam = rw[rw.optimizer == 'adam'].reset_index().iloc[0]\n",
    "\n",
    "print(rw.keys())\n",
    "print(rw.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remake weight plots with hist\n",
    "*sort the weights by highest mem to lowest mem*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import NullLocator\n",
    "\n",
    "for run in [rw_sgd, rw_adam]:\n",
    "    run['num_layer'] = int(run['num_layers'])\n",
    "    run['hidden_size'] = int(run['hidden_size'])\n",
    "    epoch = int(max(ts))\n",
    "    lay = 'fc.0.weight'\n",
    "\n",
    "    # keys are epochs, vals are dicts of all weights\n",
    "    weights_dict_dict = run['weights']\n",
    "\n",
    "    # keys are layers, vals are weight values\n",
    "#     print(weights_dict_dict.keys())\n",
    "    weights_dict = weights_dict_dict[epoch]\n",
    "#     print(weights_dict.keys())\n",
    "\n",
    "    # matrix of weights (output x input)\n",
    "    w = weights_dict[lay]\n",
    "    viz_weights.plot_weights(w, dset='mnist', C=18, dpi=120)\n",
    "                \n",
    "    plt.gca().set_axis_off()\n",
    "    plt.gca().xaxis.set_major_locator(NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(NullLocator())\n",
    "    plt.margins(0, 0)\n",
    "\n",
    "    plt.savefig(run.optimizer + '_' + str(run.hidden_size) + '_' + 'w0.pdf', bbox_inches = 'tight', pad_inches = 0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.cpu().numpy().reshape(X_train.shape[0], -1)\n",
    "W = model.state_dict()['fc.0.weight'].cpu().numpy()\n",
    "max_corr = max_corr_input(X, W)\n",
    "print('mean max corr', np.mean(max_corr))\n",
    "plt.hist(max_corr)\n",
    "plt.axvline(np.mean(max_corr), color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make alterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calc_max_corr\n",
    "\n",
    "# load model\n",
    "model = data.get_model(run)\n",
    "\n",
    "train_loader, test_loader = data.get_data_loaders(run)\n",
    "X_train, Y_train, X_test, Y_test = calc_max_corr.process_loaders(train_loader, test_loader)\n",
    "\n",
    "# load in weights\n",
    "weights_dict_tensors = {k: torch.Tensor(v) for k, v in weights_dict.items()}\n",
    "model.load_state_dict(weights_dict_tensors)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.cpu().numpy().reshape(X_train.shape[0], -1)[:1000]\n",
    "Y = Y_train[:1000]\n",
    "X = X[Y.argsort()] # sort X by class\n",
    "W1 = model.state_dict()['fc.0.weight'].cpu().numpy()\n",
    "Z = X @ W1.T\n",
    "\n",
    "# Z[:, -50:] = np.tile(Y[Y.argsort()], 50).reshape(-1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(Variable(X_train)).data.cpu().numpy().argmax(axis=1)\n",
    "accs = preds==Y_train\n",
    "print('mean acc', np.mean(accs))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
