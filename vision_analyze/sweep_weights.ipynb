{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as oj\n",
    "import sys, time\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "sys.path.insert(1, oj(sys.path[0], '..', 'vision_fit'))  # insert parent path\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import math\n",
    "# plt.style.use('dark_background')\n",
    "from mog_fit import data\n",
    "from collections import OrderedDict\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from mog_analyze import viz\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from vision_fit import data\n",
    "\n",
    "import viz_weights\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import style\n",
    "style.set_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load results from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depending on how much is saved, this may take a while\n",
    "out_dir = '/scratch/users/vision/yu_dl/raaz.rsk/track_acts/sweep_full_real'\n",
    "fnames = sorted([fname for fname in os.listdir(out_dir) if not 'mnist' in fname and \n",
    "                 'numlays=4' in fname and \n",
    "                 'batchsize=100' in fname and not 'batchsize=1000' in fname])\n",
    "#                   and \n",
    "#                  'numlays=4' in fname]) # and \n",
    "#                  'batchsize=100' in fname and \n",
    "#                  not 'batchsize=1000' in fname])\n",
    "weights_list = [pd.Series(pkl.load(open(oj(out_dir, fname), \"rb\"))) for fname in tqdm(fnames) \n",
    "                if fname.startswith('weights')]\n",
    "results_weights = pd.concat(weights_list, axis=1).T.infer_objects()\n",
    "\n",
    "results_list = [pd.Series(pkl.load(open(oj(out_dir, fname), \"rb\"))) for fname in tqdm(fnames) \n",
    "                if not fname.startswith('weights')]\n",
    "results = pd.concat(results_list, axis=1).T.infer_objects()\n",
    "\n",
    "save_dir = 'results_weights'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "print('loaded', results_weights.shape[0], 'runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(results.num_layers)\n",
    "np.unique(results.optimizer, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run all max corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_max = pd.DataFrame({'max_corr1': mean_max_corrs1, 'max_corr2': mean_max_corrs2, 'max_corr3': mean_max_corrs3, \n",
    "                       'max_corr4': mean_max_corrs4, 'train_acc_final': train_accs, \n",
    "                       'num_layers': results_weights_filt['num_layers'], 'optimizer': results_weights_filt['optimizer'],\n",
    "                       'batch_size': results_weights_filt['batch_size'], 'lr': results_weights_filt['lr']})\n",
    "pd_max.to_pickle('max_corr_mnist_4+7lay.pkl')\n",
    "# pkl.dump(pd_max, 'max_corr_small.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_max = pd.read_pickle('max_corr_cifar_4+7lay_full.pkl') # max_corr_mnist_4+7lay.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "R, C = 1, 4\n",
    "plt.subplot(R, C, 1)\n",
    "sns.scatterplot(pd_max['train_acc_final'], pd_max['max_corr1'], hue=pd_max['optimizer'], alpha=0.4)\n",
    "plt.subplot(R, C, 2)\n",
    "sns.scatterplot(pd_max['train_acc_final'], pd_max['max_corr2'], hue=pd_max['optimizer'], alpha=0.4)\n",
    "plt.subplot(R, C, 3)\n",
    "sns.scatterplot(pd_max['train_acc_final'], pd_max['max_corr3'], hue=pd_max['optimizer'], alpha=0.4)\n",
    "plt.subplot(R, C, 4)\n",
    "sns.scatterplot(pd_max['train_acc_final'], pd_max['max_corr4'], hue=pd_max['optimizer'], alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[dset == 'cifar10'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd_max.copy()\n",
    "df = pd_max[pd_max['train_acc_final'] > 0.9]\n",
    "df = pd_max[pd_max['num_layers']==4]\n",
    "N = df.shape[0]\n",
    "print(N)\n",
    "x = np.repeat([1, 2, 3, 4], N)\n",
    "y = np.concatenate([df['max_corr' + str(i)] for i in range(1, 5)])\n",
    "opt = np.tile(df['optimizer'], 4)\n",
    "sns.scatterplot(x, y, hue=opt, alpha=0.2)\n",
    "plt.xlabel('layer for max corr')\n",
    "plt.ylabel('max corr')\n",
    "# print(df[['max_corr2', 'optimizer']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(np.log10(df['lr']), df['max_corr1'], hue=df['optimizer'], alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set the params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 7\n",
    "epoch = 151\n",
    "lay = 'fc.0.weight'\n",
    "num_to_plot = 225\n",
    "# vs = {'lr': 0.01, 'seed': 0, 'optimizer': 'adam'}\n",
    "vs = {'lr': 0.001, 'seed': 0, 'optimizer': 'adam', 'batch_size': 100}\n",
    "\n",
    "# filter out certain things\n",
    "results_weights = results_weights[results_weights['shuffle_labels'] == False]\n",
    "\n",
    "# filter appropriate run\n",
    "run = results_weights[(results_weights['lr'] == vs['lr'])]\n",
    "run = run[(run['optimizer'] == vs['optimizer'])]\n",
    "run = run[(run['seed'] == vs['seed'])]\n",
    "run = run[(run['batch_size'] == vs['batch_size'])]\n",
    "\n",
    "# load corresponding accs\n",
    "run_accs = results[(results['lr'] == vs['lr'])]\n",
    "run_accs = run_accs[(run_accs['optimizer'] == vs['optimizer'])]\n",
    "run_accs = run_accs[(run_accs['seed'] == vs['seed'])]\n",
    "run_accs = run_accs[(run_accs['batch_size'] == vs['batch_size'])]\n",
    "run_acc = run_accs.iloc[0]\n",
    "plt.plot(run_acc['its'], run_acc['accs_train'])\n",
    "plt.plot(run_acc['its'], run_acc['accs_test'])\n",
    "# print(run_accs['accs_train'][:30])\n",
    "\n",
    "\n",
    "# cast variables to correct types\n",
    "run = run.iloc[0]\n",
    "run['num_layer'] = int(run['num_layers'])\n",
    "run['hidden_size'] = int(run['hidden_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 151\n",
    "lay = 'fc.0.weight'\n",
    "num_to_plot = 100\n",
    "\n",
    "\n",
    "run = results_weights.iloc[0]\n",
    "run['num_layer'] = int(run['num_layers'])\n",
    "run['hidden_size'] = int(run['hidden_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys are epochs, vals are dicts of all weights\n",
    "weights_dict_dict = run['weights']\n",
    "\n",
    "# keys are layers, vals are weight values\n",
    "weights_dict = weights_dict_dict[epoch]\n",
    "\n",
    "# matrix of weights (output x input\n",
    "w = weights_dict[lay]\n",
    "\n",
    "viz_weights.plot_weights(w[:num_to_plot], dset='cifar10')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calc_max_corr\n",
    "\n",
    "# load model\n",
    "model = data.get_model(run)\n",
    "\n",
    "train_loader, test_loader = data.get_data_loaders(run)\n",
    "X_train, Y_train, X_test, Y_test = calc_max_corr.process_loaders(train_loader, test_loader)\n",
    "\n",
    "# load in weights\n",
    "weights_dict_tensors = {k: torch.Tensor(v) for k, v in weights_dict.items()}\n",
    "model.load_state_dict(weights_dict_tensors)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.cpu().numpy().reshape(X_train.shape[0], -1)[:1000]\n",
    "Y = Y_train[:1000]\n",
    "X = X[Y.argsort()] # sort X by class\n",
    "W1 = model.state_dict()['fc.0.weight'].cpu().numpy()\n",
    "Z = X @ W1.T\n",
    "\n",
    "# Z[:, -50:] = np.tile(Y[Y.argsort()], 50).reshape(-1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12), dpi=300)\n",
    "plt.imshow(np.vstack((Z)), interpolation=None)\n",
    "plt.xlabel('neuron num')\n",
    "plt.ylabel('samples')\n",
    "plt.grid('off')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Y[Y.argsort()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check the acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(Variable(X_train)).data.cpu().numpy().argmax(axis=1)\n",
    "accs = preds==Y_train\n",
    "print('mean acc', np.mean(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "mean_accs = np.zeros(10)\n",
    "for c in range(10):\n",
    "    idxs_c = Y_train == c\n",
    "    mean_accs[c] = np.mean(accs[idxs_c])\n",
    "plt.plot(range(10), mean_accs, 'o')\n",
    "plt.xlabel('class')\n",
    "plt.ylabel('acc')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.cpu().numpy().reshape(X_train.shape[0], -1)\n",
    "W = model.state_dict()['fc.0.weight'].cpu().numpy()\n",
    "max_corr = max_corr_input(X, W)\n",
    "print('mean max corr', np.mean(max_corr))\n",
    "plt.hist(max_corr)\n",
    "plt.axvline(np.mean(max_corr), color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
