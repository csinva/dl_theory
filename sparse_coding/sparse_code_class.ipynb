{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from os.path import join as oj\n",
    "import sys\n",
    "sys.path.append('../vision_fit')\n",
    "sys.path.append('../vision_analyze')\n",
    "import viz_weights\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise\n",
    "import matplotlib.pyplot as plt\n",
    "import models\n",
    "from dim_reduction import *\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning\n",
    "from tqdm import tqdm\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "(1000, 3072)\n"
     ]
    }
   ],
   "source": [
    "# load dset\n",
    "root = oj('/scratch/users/vision/yu_dl/raaz.rsk/data', 'cifar10')\n",
    "trans = transforms.Compose([transforms.ToTensor()])\n",
    "test_set = dset.CIFAR10(root=root, train=False, download=True)\n",
    "X_test = test_set.test_data\n",
    "Y_test = np.array(test_set.test_labels)\n",
    "lab_dict = {0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}\n",
    "\n",
    "# filter by a class\n",
    "idxs = Y_test==1\n",
    "X = X_test[idxs]\n",
    "Y = Y_test[idxs]\n",
    "\n",
    "# look at an image or 2\n",
    "# num = 0\n",
    "# plt.imshow(X[num], interpolation=None)\n",
    "# plt.title(lab_dict[Y[num]])\n",
    "# plt.show()\n",
    "\n",
    "X_d = X.reshape(X.shape[0], -1)\n",
    "print(X_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.0\n",
    "n_iter = 1\n",
    "n_components = 256\n",
    "batch_size = 100\n",
    "\n",
    "dico = MiniBatchDictionaryLearning(n_components=n_components, alpha=alpha, n_iter=n_iter, n_jobs=1, batch_size=batch_size) \n",
    "for i in tqdm(range(50000)):\n",
    "    V = dico.fit(X_d)\n",
    "    if i % 100 == 0:\n",
    "        np.save('sparse_cifar/bases_iters=' + str(i) + '_alpha=' + str(alpha) + '_ncomps=' + str(n_components) + '.npy', V.components_)        \n",
    "#         viz_weights.plot_weights(V.components_, dset='cifar10')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
