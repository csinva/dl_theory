{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as oj\n",
    "import sys, time\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import math\n",
    "# plt.style.use('dark_background')\n",
    "from mog_fit import data\n",
    "from collections import OrderedDict\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from mog_analyze import viz\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.stats import entropy\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load in imagenet dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Data loading code\n",
    "data_dir = '/scratch/users/vision/data/cv/imagenet_full'\n",
    "traindir = os.path.join(data_dir, 'train')\n",
    "valdir = os.path.join(data_dir, 'val')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "batch_size = 1\n",
    "num_workers = 1\n",
    "'''\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=False,\n",
    "    num_workers=num_workers, pin_memory=True)\n",
    "'''\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dset.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize])),\n",
    "    batch_size=batch_size, shuffle=False, \n",
    "    num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load in some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "def get_model(s):\n",
    "    if s == 'densenet':\n",
    "        model = models.densenet161(pretrained=True)\n",
    "    elif s == 'alexnet':\n",
    "        model = models.alexnet(pretrained=True)\n",
    "    elif s == 'resnet18':\n",
    "        model = models.resnet18(pretrained=True)\n",
    "    elif s == 'vgg16':\n",
    "        model = models.vgg16(pretrained=True)\n",
    "    elif s == 'inception_v3':\n",
    "        model = models.inception_v3(pretrained=True)\n",
    "    return model.cuda()\n",
    "\n",
    "model = get_model('alexnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f7652cfada0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def hook(module, input, output):\n",
    "#     print(module.__class__.__name__)\n",
    "    print(module)\n",
    "    outputs.append(output)\n",
    "    \n",
    "def calc_max_corr(val_loader, outputs, W):\n",
    "    for x in val_loader:\n",
    "        ims = x[0].cuda()\n",
    "        break\n",
    "    _ = model(Variable(ims))\n",
    "    \n",
    "    \n",
    "outputs= []\n",
    "# loop over hooks / Ws here\n",
    "model.classifier[1].register_forward_hook(hook)\n",
    "calc_max_corr(loader, outputs, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = x[0][1].numpy().transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
