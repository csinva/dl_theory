{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes torch.Size([500, 784]) (500, 784)\n",
      "shapes torch.Size([256, 500]) (256, 500)\n",
      "shapes torch.Size([10, 256]) (10, 256)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from os.path import join as oj\n",
    "import sys\n",
    "sys.path.append('../vision')\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise\n",
    "\n",
    "import models\n",
    "from dim_reduction import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# reduce model by projecting onto pcs that explain \"percent_to_explain\"\n",
    "def reduce_model(model, percent_to_explain=0.85):\n",
    "    model_r = deepcopy(model)\n",
    "    weight_dict = model_r.state_dict()\n",
    "    weight_dict_new = deepcopy(model_r.state_dict())\n",
    "#     print(weight_dict)\n",
    "    for layer_name in weight_dict.keys():\n",
    "        if 'weight' in layer_name:\n",
    "            w = weight_dict[layer_name]\n",
    "            \n",
    "            # get number of components\n",
    "            pca = PCA(n_components=w.shape[1])\n",
    "            pca.fit(w)\n",
    "            explained_vars = pca.explained_variance_ratio_\n",
    "            dim, perc_explained = 0, 0\n",
    "            while perc_explained <= percent_to_explain:\n",
    "                perc_explained += explained_vars[dim]\n",
    "                dim += 1\n",
    "            \n",
    "            # actually project\n",
    "            pca = PCA(n_components=dim)            \n",
    "            w2 = pca.inverse_transform(pca.fit_transform(w))\n",
    "            print('shapes', w.shape, w2.shape)\n",
    "            weight_dict_new[layer_name] = torch.Tensor(w2)\n",
    "            \n",
    "    model_r.load_state_dict(weight_dict_new)\n",
    "    return model_r\n",
    "\n",
    "             \n",
    "modelm = models.MnistNet()        \n",
    "modelr = reduce_model(modelm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 784)\n"
     ]
    }
   ],
   "source": [
    "print(modelm.state_dict()['fc1.weight'][:10].numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params_vision import p\n",
    "np.random.seed(p.seed) \n",
    "torch.manual_seed(p.seed)    \n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "batch_size = 100\n",
    "root = oj('/scratch/users/vision/yu_dl/raaz.rsk/data', p.dset)\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "\n",
    "\n",
    "## load mnist dataset     \n",
    "\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "train_set = dset.MNIST(root=root, train=True, transform=trans, download=True)\n",
    "test_set = dset.MNIST(root=root, train=False, transform=trans, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False)\n",
    "model = models.MnistNet()  \n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseCoder(dictionary=None, n_jobs=1, split_sign=False,\n",
      "      transform_algorithm='omp', transform_alpha=None,\n",
      "      transform_n_nonzero_coefs=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import SparseCoder\n",
    "N = 100\n",
    "data = train_set.train_data.numpy()[:N].reshape(N, -1)\n",
    "sc = SparseCoder(data)\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MNIST' object has no attribute 'targets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2d0b5553ff43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MNIST' object has no attribute 'targets'"
     ]
    }
   ],
   "source": [
    "train_set.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.train_labels = torch.Tensor(np.random.randint(0, 10, 60000)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randint(0, 10, 60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.0.post4'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "root = oj('/scratch/users/vision/yu_dl/raaz.rsk/data', 'cifar10')\n",
    "train_set = dset.CIFAR10(root=root, train=True, download=True, transform=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, int)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set.train_labels), type(train_set.train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
