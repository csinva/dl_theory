{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes torch.Size([500, 784]) (500, 784)\n",
      "shapes torch.Size([256, 500]) (256, 500)\n",
      "shapes torch.Size([10, 256]) (10, 256)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from os.path import join as oj\n",
    "import sys\n",
    "sys.path.append('../vision_fit')\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise\n",
    "import matplotlib.pyplot as plt\n",
    "import models\n",
    "from dim_reduction import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# reduce model by projecting onto pcs that explain \"percent_to_explain\"\n",
    "def reduce_model(model, percent_to_explain=0.85):\n",
    "    model_r = deepcopy(model)\n",
    "    weight_dict = model_r.state_dict()\n",
    "    weight_dict_new = deepcopy(model_r.state_dict())\n",
    "#     print(weight_dict)\n",
    "    for layer_name in weight_dict.keys():\n",
    "        if 'weight' in layer_name:\n",
    "            w = weight_dict[layer_name]\n",
    "            \n",
    "            # get number of components\n",
    "            pca = PCA(n_components=w.shape[1])\n",
    "            pca.fit(w)\n",
    "            explained_vars = pca.explained_variance_ratio_\n",
    "            dim, perc_explained = 0, 0\n",
    "            while perc_explained <= percent_to_explain:\n",
    "                perc_explained += explained_vars[dim]\n",
    "                dim += 1\n",
    "            \n",
    "            # actually project\n",
    "            pca = PCA(n_components=dim)            \n",
    "            w2 = pca.inverse_transform(pca.fit_transform(w))\n",
    "            print('shapes', w.shape, w2.shape)\n",
    "            weight_dict_new[layer_name] = torch.Tensor(w2)\n",
    "            \n",
    "    model_r.load_state_dict(weight_dict_new)\n",
    "    return model_r\n",
    "\n",
    "             \n",
    "modelm = models.MnistNet()        \n",
    "modelr = reduce_model(modelm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 784)\n"
     ]
    }
   ],
   "source": [
    "print(modelm.state_dict()['fc1.weight'][:10].numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight torch.Size([500, 784])\n",
      "True\n",
      "fc1.bias torch.Size([500])\n",
      "True\n",
      "fc2.weight torch.Size([256, 500])\n",
      "False\n",
      "fc2.bias torch.Size([256])\n",
      "False\n",
      "fc3.weight torch.Size([10, 256])\n",
      "False\n",
      "fc3.bias torch.Size([10])\n",
      "False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from params_vision import p\n",
    "np.random.seed(p.seed) \n",
    "torch.manual_seed(p.seed)    \n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "batch_size = 100\n",
    "root = oj('/scratch/users/vision/yu_dl/raaz.rsk/data', p.dset)\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "\n",
    "\n",
    "## load mnist dataset     \n",
    "\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "train_set = dset.MNIST(root=root, train=True, transform=trans, download=True)\n",
    "test_set = dset.MNIST(root=root, train=False, transform=trans, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False)\n",
    "model = models.MnistNet()  \n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MNIST' object has no attribute 'targets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2d0b5553ff43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MNIST' object has no attribute 'targets'"
     ]
    }
   ],
   "source": [
    "train_set.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cb4ffc1c824a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "train_set.train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "d = torch.Tensor(np.random.randn(60000, 28, 28))\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.train_labels = torch.Tensor(np.random.randint(0, 10, 60000)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 4, ..., 6, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 10, 60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "test_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "13\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(bars[0])\n",
    "print(labs[0])\n",
    "print(np.max(labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "root = oj('/scratch/users/vision/yu_dl/raaz.rsk/data', 'cifar10')\n",
    "train_set = dset.CIFAR10(root=root, train=True, download=True, transform=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, int)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set.train_labels), type(train_set.train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
