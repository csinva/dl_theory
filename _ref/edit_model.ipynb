{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes torch.Size([500, 784]) (500, 784)\n",
      "shapes torch.Size([256, 500]) (256, 500)\n",
      "shapes torch.Size([10, 256]) (10, 256)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from os.path import join as oj\n",
    "import sys\n",
    "sys.path.append('../vision')\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise\n",
    "\n",
    "import models\n",
    "from dim_reduction import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# reduce model by projecting onto pcs that explain \"percent_to_explain\"\n",
    "def reduce_model(model, percent_to_explain=0.85):\n",
    "    model_r = deepcopy(model)\n",
    "    weight_dict = model_r.state_dict()\n",
    "    weight_dict_new = deepcopy(model_r.state_dict())\n",
    "#     print(weight_dict)\n",
    "    for layer_name in weight_dict.keys():\n",
    "        if 'weight' in layer_name:\n",
    "            w = weight_dict[layer_name]\n",
    "            \n",
    "            # get number of components\n",
    "            pca = PCA(n_components=w.shape[1])\n",
    "            pca.fit(w)\n",
    "            explained_vars = pca.explained_variance_ratio_\n",
    "            dim, perc_explained = 0, 0\n",
    "            while perc_explained <= percent_to_explain:\n",
    "                perc_explained += explained_vars[dim]\n",
    "                dim += 1\n",
    "            \n",
    "            # actually project\n",
    "            pca = PCA(n_components=dim)            \n",
    "            w2 = pca.inverse_transform(pca.fit_transform(w))\n",
    "            print('shapes', w.shape, w2.shape)\n",
    "            weight_dict_new[layer_name] = torch.Tensor(w2)\n",
    "            \n",
    "    model_r.load_state_dict(weight_dict_new)\n",
    "    return model_r\n",
    "\n",
    "             \n",
    "modelm = models.MnistNet()        \n",
    "modelr = reduce_model(modelm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 784)\n"
     ]
    }
   ],
   "source": [
    "print(modelm.state_dict()['fc1.weight'][:10].numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "relu2 (256, 1000)\n",
      "fc1 (500, 1000)\n",
      "relu1 (500, 1000)\n",
      "fc2 (256, 1000)\n",
      "fc3 (10, 1000)\n",
      "shape (256, 1000) ncomps= 1000\n",
      "shape (500, 1000) ncomps= 1000\n",
      "shape (500, 1000) ncomps= 1000\n",
      "shape (256, 1000) ncomps= 1000\n",
      "shape (10, 1000) ncomps= 1000\n",
      "vars relu2 (256,)\n",
      "vars fc1 (500,)\n",
      "vars relu1 (500,)\n",
      "vars fc2 (256,)\n",
      "vars fc3 (10,)\n",
      "relu2 (256, 1000)\n",
      "fc1 (500, 1000)\n",
      "relu1 (500, 1000)\n",
      "fc2 (256, 1000)\n",
      "fc3 (10, 1000)\n",
      "shape (256, 1000) ncomps= 1000\n",
      "shape (500, 1000) ncomps= 1000\n",
      "shape (500, 1000) ncomps= 1000\n",
      "shape (256, 1000) ncomps= 1000\n",
      "shape (10, 1000) ncomps= 1000\n",
      "vars relu2 (256,)\n",
      "vars fc1 (500,)\n",
      "vars relu1 (500,)\n",
      "vars fc2 (256,)\n",
      "vars fc3 (10,)\n"
     ]
    }
   ],
   "source": [
    "from params_vision import p\n",
    "np.random.seed(p.seed) \n",
    "torch.manual_seed(p.seed)    \n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "batch_size = 100\n",
    "root = oj('/scratch/users/vision/yu_dl/raaz.rsk/data', p.dset)\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "\n",
    "\n",
    "## load mnist dataset     \n",
    "\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "train_set = dset.MNIST(root=root, train=True, transform=trans, download=True)\n",
    "test_set = dset.MNIST(root=root, train=False, transform=trans, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False)\n",
    "model = models.MnistNet()  \n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    " \n",
    "    \n",
    "def calc_activation_dims(use_cuda, model, dset_train, dset_test, calc_activations=0):\n",
    "    if calc_activations > 0:\n",
    "        dims = []\n",
    "        for d in [dset_train, dset_test]:\n",
    "\n",
    "            loader = torch.utils.data.DataLoader(\n",
    "                     dataset=d,\n",
    "                     batch_size=calc_activations,\n",
    "                     shuffle=False)\n",
    "\n",
    "#             print(calc_activations)\n",
    "            # just use 1 big batch\n",
    "            for batch_idx, (x, target) in enumerate(loader):\n",
    "                if use_cuda:\n",
    "                    x, target = x.cuda(), target.cuda()\n",
    "#                 print(x.shape)\n",
    "                x = Variable(x, volatile=True)\n",
    "                y = model.forward_all(x)\n",
    "                y = {key: y[key].data.cpu().numpy().T for key in y.keys()}\n",
    "#                 print(y.keys())\n",
    "                for key in y.keys():\n",
    "                    print(key, y[key].shape)\n",
    "#                 print(y['fc1'].shape)\n",
    "                if batch_idx >= 0:\n",
    "                    break\n",
    "            act_var_dict = get_explained_var_from_weight_dict(y, activation=True)\n",
    "            for key in act_var_dict:\n",
    "                print('vars', key, act_var_dict[key].shape)\n",
    "#             dims.append()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "print(p.calc_activations)\n",
    "\n",
    "calc_activation_dims(use_cuda, model, train_set, test_set, calc_activations=p.calc_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
