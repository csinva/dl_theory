{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.autograd\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "from params_poly import p\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "from os.path import join as oj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as pylab\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def set_style():\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    label_size = 12\n",
    "    mpl.rcParams['xtick.labelsize'] = label_size \n",
    "    mpl.rcParams['ytick.labelsize'] = label_size \n",
    "    mpl.rcParams['axes.labelsize'] = label_size\n",
    "    mpl.rcParams['axes.titlesize'] = label_size\n",
    "    mpl.rcParams['figure.titlesize'] = label_size\n",
    "    mpl.rcParams['lines.markersize'] = 20\n",
    "    mpl.rcParams['lines.linewidth'] = 3.\n",
    "    mpl.rcParams['grid.linewidth'] = 1.\n",
    "    mpl.rcParams['legend.fontsize'] = label_size\n",
    "    pylab.rcParams['xtick.major.pad']=3\n",
    "    pylab.rcParams['ytick.major.pad']=3\n",
    "\n",
    "    pylab.rcParams['figure.facecolor']='white'\n",
    "    pylab.rcParams['axes.facecolor']='white'\n",
    "    # mpl.rcParams['figure.figsize'] = [12, 10]\n",
    "    # mpl.rcParams.keys()\n",
    "    # Say, \"the default sans-serif font is COMIC SANS\"\n",
    "    # mpl.rcParams['font.serif'] = 'Times New Roman'\n",
    "    # # Then, \"ALWAYS use sans-serif fonts\"\n",
    "    # mpl.rcParams['font.family'] = \"Serif\"\n",
    "\n",
    "import pandas as pd\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_el(x):\n",
    "    return x * x\n",
    "\n",
    "def cube_el(x):\n",
    "    return x * x * x\n",
    "\n",
    "def sin_el(x):\n",
    "    return np.sin(x * 2 * np.pi / 100)\n",
    "\n",
    "def make_data(func, N=4):\n",
    "    X = np.linspace(0, 100, N)\n",
    "    X_grid = np.linspace(-80, 120, 1000)\n",
    "    Y = np.apply_along_axis(func, 0, X)\n",
    "    Y_grid = np.apply_along_axis(func, 0, X_grid)            \n",
    "    return X, Y, X_grid, Y_grid\n",
    "\n",
    "\n",
    "def seed(p, repeat):\n",
    "    s = p.seed + repeat * 13913\n",
    "    # set random seed        \n",
    "    np.random.seed(s) \n",
    "    torch.manual_seed(s)    \n",
    "    random.seed(s)\n",
    "    \n",
    "## network\n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, num_layers, input_size, hidden_size, output_size):\n",
    "        # num_layers is number of weight matrices\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # for one layer nets\n",
    "        if num_layers == 1:\n",
    "            self.fc = nn.ModuleList([nn.Linear(input_size, output_size)])\n",
    "        else:\n",
    "            self.fc = nn.ModuleList([nn.Linear(input_size, hidden_size)])\n",
    "            self.fc.extend([nn.Linear(hidden_size, hidden_size) for i in range(num_layers - 2)])\n",
    "            self.fc.append(nn.Linear(hidden_size, output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x.view(-1, self.input_size)\n",
    "        for i in range(len(self.fc) - 1):\n",
    "            y = F.relu(self.fc[i](y))\n",
    "        return self.fc[-1](y)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "freeze = False    \n",
    "hidden_size = 1024\n",
    "repeats = 5\n",
    "opt = 'adam'\n",
    "lr = 1e-1\n",
    "N = 4\n",
    "func = cube_el # square\n",
    "X, Y, X_grid, Y_grid = make_data(func, N)\n",
    "plt.plot(X, Y, 'o')\n",
    "plt.plot(X_grid, Y_grid, '--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t, Y_t = Variable(torch.Tensor(X)).cuda(), Variable(torch.Tensor(Y)).cuda()\n",
    "models = []\n",
    "num_hiddens = []\n",
    "losses = []\n",
    "seeds = []\n",
    "opts = []\n",
    "lrs = []\n",
    "\n",
    "for i, nh in tqdm(enumerate([1, 2])):\n",
    "    for repeat in range(repeats):\n",
    "        seed(p, repeat)\n",
    "        model = LinearNet(nh, input_size=1, hidden_size=hidden_size, output_size=1).cuda()\n",
    "\n",
    "        if freeze:\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'fc.0' in name:\n",
    "                    param.requires_grad = True \n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "\n",
    "        if opt == 'adam':\n",
    "            optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "                              lr=lr) # wow Adam does way better\n",
    "        else:\n",
    "            optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr) # 1e6 worked \n",
    "        criterion =  torch.nn.MSELoss()\n",
    "        for batch_idx in range(1000):\n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            loss = criterion(model(X_t), Y_t)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Apply gradients\n",
    "            optimizer.step()\n",
    "#         print('loss: {:.6f} after {} batches'.format(loss.data[0], batch_idx))\n",
    "\n",
    "        \n",
    "        # saving\n",
    "        models.append(deepcopy(model))\n",
    "        num_hiddens.append(nh)\n",
    "        losses.append(loss.data[0])\n",
    "        seeds.append(repeat)\n",
    "        opts.append(opt)\n",
    "        lrs.append(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_states = [model.cpu().state_dict() for model in models]\n",
    "d = {'model': models, 'num_hidden': num_hiddens, \n",
    "     'loss': losses, 'seed': seeds, 'optimizer': opts, 'lr': lr}\n",
    "\n",
    "# results.to_pickle('poly_runs_sin.pkl')\n",
    "# pkl.dump(d, open('poly_runs_sin' + '.pkl', 'wb'))\n",
    "\n",
    "results = pd.DataFrame.from_dict(d)       \n",
    "# results = pd.read_pickle('poly_runs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(X, Y, X_grid, Y_grid, model, repeat):\n",
    "    Xgrid = Variable(torch.Tensor(X_grid))\n",
    "    yhat = model(Xgrid.cuda()).data.cpu().numpy()\n",
    "    plt.plot(Xgrid.data.numpy(), yhat, label='fit ' + str(repeat), alpha=0.5)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 12), dpi=100, facecolor='white')\n",
    "R, C = 2, 3\n",
    "X, Y, X_grid, Y_grid = make_data(func, N)\n",
    "\n",
    "for i, nh in enumerate(sorted(set(results.num_hidden))): #([1, 2, 3, 4, 5, 7]):\n",
    "    plt.subplot(R, C, i + 1)\n",
    "    plt.plot(X, Y, 'o', label='orig data')\n",
    "    plt.plot(X_grid, Y_grid, '--', label='func') \n",
    "    plt.ylim((-500000, 1500000))\n",
    "    #     plt.ylim((-2000, 12000))\n",
    "\n",
    "#     plt.ylim((-1.5, 1.5))\n",
    "\n",
    "    plt.title(str(nh) + ' lays')\n",
    "    for repeat in range(repeats):\n",
    "\n",
    "        r = results[results.num_hidden == nh]\n",
    "        r = r[r.seed == repeat]\n",
    "        model = r.iloc[0].model.cuda()\n",
    "            \n",
    "        R, C = 2, 3\n",
    "        plot_model(X, Y, X_grid, Y_grid, model, repeat)\n",
    "        \n",
    "        # saving\n",
    "        models.append(deepcopy(model))\n",
    "        num_hiddens.append(nh)\n",
    "        losses.append(loss.data[0])\n",
    "        seeds.append(repeat)\n",
    "        opts.append(opt)\n",
    "        lrs.append(lr)\n",
    "        \n",
    "    if i == 0:\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
